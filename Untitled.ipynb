{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89785938-9333-446a-8f7d-158a58b27690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2728404f-95c2-4d18-b111-2f39ed4344fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bask/homes/h/hdjd5168/vjgo8416-ms-img-pc/marji/envmfvne/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.12.1.post200'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "torch.__version__\n",
    "# the interference_mode needs a version of torch v1.9 so I have changed it to no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac56149c-5ddf-484d-a289-3d7f359678b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e6ec75-0045-4fc1-aa1b-2d4fd9cb8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vne.vae import ShapeVAE, ShapeSimilarityLoss\n",
    "from vne.special.protein_AM import Protein_PDB, similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa91be87-cae4-4bd5-b2a9-7ce6f2fe1e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "PDB_path = '/bask/homes/h/hdjd5168/vjgo8416-ms-img-pc/marji/protein_vne/pdbs/'\n",
    "pdb_list = os.listdir(PDB_path)\n",
    "pdb_name =[ PDB_path + name for name in pdb_list]\n",
    "print(len(pdb_name))\n",
    "slice_b = 0\n",
    "slice_e = 2\n",
    "#pdb_name = pdb_name[slice_b:slice_e]\n",
    "pdb_list = [n for n in pdb_list if n[-8] == '2' ]\n",
    "\n",
    "\n",
    "pdb_name = [n for n in pdb_name if n[-8] == '2' ]\n",
    "pdb_list = pdb_list[0:2]\n",
    "pdb_name = pdb_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af99b6e6-e240-4bf7-8b6e-c09646ca1993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14457, 14457, 14457]\n",
      "[14457, 14457, 14457]\n",
      "[2799, 2799, 2799]\n",
      "[2799, 2799, 2799]\n",
      "[14457, 14457, 14457]\n",
      "[2799, 2799, 2799]\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "molecules = [Protein_PDB(filename) for filename in pdb_name]\n",
    "lookup = similarity_matrix(molecules)\n",
    "print(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80470932-2d4d-4412-9963-9d3a1084753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookup_copy = lookup\n",
    "def plot_soap(lookup):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    im = ax.imshow(lookup, vmin=-1, vmax=1, cmap=plt.cm.get_cmap('RdBu'))\n",
    "    ax.set_title('Shape similarity matrix - SOAP')\n",
    "    ax.set_xticks(np.arange(0, len(pdb_name)))\n",
    "    ax.set_xticklabels(pdb_list)\n",
    "    ax.set_yticks(np.arange(0, len(pdb_name)))\n",
    "    ax.set_yticklabels(pdb_list)\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.savefig('similarity_SOAP_rot.png', dpi=144)\n",
    "#plot_soap(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b024c90b-6e79-476e-9759-7639e83e7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA_UPPER = 45\n",
    "THETA_LOWER = -45\n",
    "\n",
    "\n",
    "CTF_PADDING = 64\n",
    "NUM_EULER_ANGLES = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d9c121c-47a8-49d0-b1be-72bbc50017f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9c43a5-39e8-498d-ba1b-7fa1783362db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_path = '/bask/projects/v/vjgo8416-ms-img-pc/marji/parakeet/ecoli/'\n",
    "mrc_path + pdb_list[0][0:4] +'/' + pdb_list[0]\n",
    "mrc_file = mrcfile.open(mrc_path + pdb_list[0][0:4] +'/' + 'rec.mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61d32fa-d88d-4257-8638-f8b993f7649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_path = '/bask/projects/v/vjgo8416-ms-img-pc/marji/parakeet/tutorials/'\n",
    "mrc_file = mrcfile.open(mrc_path +'rec.mrc')\n",
    "mrc = mrc_file.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d9f2a6-ec03-45a6-b4c3-a18c54a164b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def plot_mrc(mrc):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = np.linspace(0, 200, num=mrc.shape[0], endpoint=False)\n",
    "    y = np.linspace(0, 200, num=mrc.shape[1], endpoint=False)\n",
    "    z = np.linspace(0, 200, num=mrc.shape[2], endpoint=False)\n",
    "    X, Y = np.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "    @interact(s = (0,199,1))\n",
    "    def update(s):\n",
    "        [l.remove() for l in ax.lines]    \n",
    "        plt.contour(X, Y, mrc[:,:,s])\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "#plot_mrc(mrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab5a51e-d51a-42f5-b868-fc58c9bfde3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import rotate\n",
    "from pathlib import Path\n",
    "import vne.base as base\n",
    "\n",
    "class MoleculesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, molecules : str):\n",
    "        self.filepath = Path('/bask/projects/v/vjgo8416-ms-img-pc/marji/parakeet/ecoli/mrc_outs/')\n",
    "        self.molecules = os.listdir(self.filepath)\n",
    "        \n",
    "        #[path.name for path in (self.filepath).iterdir()\n",
    "        #    if path.is_dir()]            \n",
    "\n",
    "                \n",
    "    def keys(self):\n",
    "        return list(self.molecules)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        mrc_path =  '/bask/projects/v/vjgo8416-ms-img-pc/marji/parakeet/ecoli/mrc_outs/'\n",
    "        mol = np.random.choice(self.molecules)\n",
    "        mrc_file = mrcfile.open(mrc_path + mol)\n",
    "        mrc = mrc_file.data\n",
    "        deg_per_rot = 15\n",
    "        angle = np.random.randint(THETA_LOWER, THETA_UPPER,size=(NUM_EULER_ANGLES, ))\n",
    "    \n",
    "        for ax in range(angle.size):\n",
    "            theta = angle[ax] * deg_per_rot\n",
    "            axes = (ax, (ax+1) % angle.size)\n",
    "            mrc = rotate(mrc, theta, axes=axes, order=1, reshape=False)\n",
    "\n",
    "        mrc = np.clip(mrc, -1, 1)\n",
    "        mrc = torch.as_tensor(mrc[np.newaxis, ...], dtype=torch.float32)\n",
    "        return mrc, self.molecules.index(mol)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return IMAGES_PER_EPOCH\n",
    "\n",
    "\n",
    "'''\n",
    "class MoleculesDataset(base.Datasource):\n",
    "    def __init__(self, filepath: Path):\n",
    "        super().__init__()\n",
    "        self.filepath = Path(filepath)\n",
    "        #self.mrcId = mrcId\n",
    "        \n",
    "        self._keys = [path.name for path in (self.filepath).iterdir()\n",
    "            if path.is_dir()\n",
    "        ]        \n",
    "\n",
    "        #self.molecules = simulator.keys()\n",
    "        mrc_file = mrcfile.open(mrc_path +'rec.mrc')\n",
    "        self.mrc = mrc_file.data\n",
    "        #self._cache = {}\n",
    "    def __call__(self, model_id: str) -> np.ndarray:\n",
    "        mrc = self.mrc #np.random.choice(self.molecules)\n",
    "        deg_per_rot = 15\n",
    "        angle = np.random.randint(THETA_LOWER, THETA_UPPER,size=(NUM_EULER_ANGLES, ))\n",
    "    \n",
    "        for ax in range(angle.size):\n",
    "            theta = angle[ax] * deg_per_rot\n",
    "            axes = (ax, (ax+1) % angle.size)\n",
    "            mrc = rotate(mrc, theta, axes=axes, order=1, reshape=False)\n",
    "\n",
    "        mrc = np.clip(mrc, -1, 1)\n",
    "        mrc = torch.as_tensor(mrc[np.newaxis, ...], dtype=torch.float32)\n",
    "        self._cache[model_id] = mrc\n",
    "\n",
    "        return mrc#, self.molecules.index(rotate_mrc)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return IMAGES_PER_EPOCH\n",
    "'''\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87cbaca6-795b-40ef-8060-490c924599dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2be5.mrc', '2gls.mrc', '2cmd.mrc', '4v4q.mrc', '2a0f.mrc', '2eip.mrc', '2cw0.mrc']\n"
     ]
    }
   ],
   "source": [
    "USE_MU_SIMILARITY_LOSS = False # use the mean rather than sample for calculating the similarity loss\n",
    "LEARNING_RATE = 1e-2\n",
    "KLD_WEIGHT = 1. / (64*64)\n",
    "BETA = 4.0 * KLD_WEIGHT\n",
    "GAMMA = 10.0\n",
    "LATENT_DIMS = 7\n",
    "POSE_DIMS = 1\n",
    "BATCH_SIZE = 1\n",
    "IMAGES_PER_EPOCH = 1\n",
    "EPOCHS = 1\n",
    "\n",
    "\n",
    "dataset = MoleculesDataset(mrc_path)\n",
    "print(dataset.keys())\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c784d75a-4e7d-4946-8475-09ec9ec6f958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 12, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE =  (1, 200, 200, 200)\n",
    "model = ShapeVAE(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    latent_dims=LATENT_DIMS,\n",
    "    pose_dims=POSE_DIMS,\n",
    ").to(device)\n",
    "\n",
    "#print(summary(model, (1, 1, 64, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7166c-dfd4-4ed5-ad26-e1db1f709096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2552bc62-0ad8-4980-a788-2c3d7be4c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []\n",
    "validation_loss_plot = []\n",
    "calculate_validation_loss = False\n",
    "\n",
    "reconstruction_loss = nn.MSELoss() #Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input \n",
    "similarity_loss = ShapeSimilarityLoss(lookup=torch.Tensor(lookup).to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-5)\n",
    "A= []\n",
    "\n",
    "# The loss was not converging when weight_decay = 10^-2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9f58e3-63fb-4d71-b280-1ba2ee53606c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x140608 and 345600x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m Variable(img)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ===================forward=====================\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m output, z, z_pose, mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# reconstruction loss\u001b[39;00m\n\u001b[1;32m     12\u001b[0m r_loss \u001b[38;5;241m=\u001b[39m reconstruction_loss(output, img)\n",
      "File \u001b[0;32m~/vjgo8416-ms-img-pc/marji/envmfvne/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-ms-img-pc/marji/vne/vne/vae.py:171\u001b[0m, in \u001b[0;36mShapeVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 171\u001b[0m     mu, log_var, pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterise(mu, log_var)\n\u001b[1;32m    173\u001b[0m     z_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pose, z], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-ms-img-pc/marji/vne/vne/vae.py:186\u001b[0m, in \u001b[0;36mShapeVAE.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    185\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m--> 186\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_var(encoded)\n\u001b[1;32m    188\u001b[0m     pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpose(encoded)\n",
      "File \u001b[0;32m~/vjgo8416-ms-img-pc/marji/envmfvne/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/vjgo8416-ms-img-pc/marji/envmfvne/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x140608 and 345600x7)"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        img, mol_id = data\n",
    "        #print(img.size())\n",
    "        img = Variable(img).to(device)\n",
    "        # ===================forward=====================\n",
    "\n",
    "        output, z, z_pose, mu, log_var = model(img)\n",
    "                \n",
    "        # reconstruction loss\n",
    "        r_loss = reconstruction_loss(output, img)\n",
    "        \n",
    "        # kl loss \n",
    "        # https://arxiv.org/abs/1312.6114 (equation 10 ) \n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
    "        \n",
    "        # similarity loss\n",
    "        # s_loss = similarity_loss(mol_id, mu)\n",
    "              \n",
    "        loss = r_loss+ (BETA * kld_loss)  #  + (GAMMA * s_loss) \n",
    "\n",
    "    # ===================backward====================\n",
    "        optimizer.zero_grad() # set the gradient of all optimised torch.tensors to zero\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "    # ===================log==============================\n",
    "    \n",
    "    loss_plot.append(total_loss.cpu().clone().numpy())\n",
    "    print(f\"epoch [{epoch+1}/{EPOCHS}], loss:{total_loss:.4f}, {r_loss.data}, {s_loss.data}, {kld_loss.data}\")\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == EPOCHS-1:\n",
    "        #A = montage(np.stack(A,output.cpu().data ), padding_width=2)\n",
    "        pic = to_img(output.to(device).data)\n",
    "        save_image(pic, './image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59d28e-509d-481f-9b9f-458c7376e370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87401a1-63aa-424e-8f25-694664dfcfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b2558-1e83-48b3-a807-392ae61cbf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf6396-e9fd-467e-a1b7-0d2bfcc8ee3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e125080-25b5-45c6-a156-5856f5693a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envmfvne (Conda)",
   "language": "python",
   "name": "sys_envmfvne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
